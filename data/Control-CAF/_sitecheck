cellranger  (cellranger-6.1.1)
Copyright (c) 2021 10x Genomics, Inc.  All rights reserved.
-------------------------------------------------------------------------------
Wed Mar  5 01:29:14 EST 2025

=====================================================================
System Info
uname -a
---------------------------------------------------------------------
Linux a204.anvil.rcac.purdue.edu 4.18.0-553.16.1.el8_10.x86_64 #1 SMP Thu Aug 8 17:47:08 UTC 2024 x86_64 GNU/Linux
=====================================================================

=====================================================================
Linux Distro
cat /etc/*-release | sort -u
---------------------------------------------------------------------
BUG_REPORT_URL="https://bugs.debian.org/"
HOME_URL="https://www.debian.org/"
ID=debian
NAME="Debian GNU/Linux"
PRETTY_NAME="Debian GNU/Linux 10 (buster)"
SUPPORT_URL="https://www.debian.org/support"
VERSION="10 (buster)"
VERSION_CODENAME=buster
VERSION_ID="10"
=====================================================================

=====================================================================
Kernel Build
cat /proc/version
---------------------------------------------------------------------
Linux version 4.18.0-553.16.1.el8_10.x86_64 (mockbuild@iad1-prod-build001.bld.equ.rockylinux.org) (gcc version 8.5.0 20210514 (Red Hat 8.5.0-22) (GCC)) #1 SMP Thu Aug 8 17:47:08 UTC 2024
=====================================================================

=====================================================================
glibc version
ldd --version | head -n 1
---------------------------------------------------------------------
ldd (Debian GLIBC 2.28-10) 2.28
=====================================================================

=====================================================================
CPU Model
grep -m 1 'model name' /proc/cpuinfo | cut -d ':' -f 2 | sed 's/^[ \t]*//'
---------------------------------------------------------------------
AMD EPYC 7763 64-Core Processor
=====================================================================

=====================================================================
CPU Sockets
grep 'physical id' /proc/cpuinfo | sort -u | wc -l
---------------------------------------------------------------------
2
=====================================================================

=====================================================================
CPU Cores
grep -c processor /proc/cpuinfo
---------------------------------------------------------------------
128
=====================================================================

=====================================================================
CPU Support
grep -m 1 'flags' /proc/cpuinfo | cut -d ':' -f 2 | sed 's/^\s*//'
---------------------------------------------------------------------
fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 invpcid_single hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd amd_ppin brs arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold v_vmsave_vmload vgif v_spec_ctrl umip pku ospke vaes vpclmulqdq rdpid overflow_recov succor smca fsrm
=====================================================================

=====================================================================
Memory Total
grep MemTotal /proc/meminfo | cut -d ':' -f 2 | sed 's/^[ \t]*//'
---------------------------------------------------------------------
263693772 kB
=====================================================================

=====================================================================
Disk Space
df -Ph | awk '{print $2, $3, $4}'
---------------------------------------------------------------------
Size Used Avail
16M 16K 16M
126G 0 126G
126G 0 126G
126G 5.3G 121G
11P 4.4P 6.1P
4.5T 2.0T 2.6T
126G 0 126G
50T 17T 34T
358G 2.6G 356G
16M 16K 16M
=====================================================================

=====================================================================
Filesystem Options
mount | cut -d ' ' -f 5,6
---------------------------------------------------------------------
overlay (ro,nodev,relatime,lowerdir=/var/lib/apptainer/mnt/session/overlay-lowerdir:/var/lib/apptainer/mnt/session/rootfs)
devtmpfs (rw,nosuid,size=131817916k,nr_inodes=32954479,mode=755)
tmpfs (rw)
devpts (rw,relatime,gid=5,mode=620,ptmxmode=000)
mqueue (rw,relatime)
hugetlbfs (rw,relatime,pagesize=2M)
tmpfs (rw,nosuid,nodev,relatime,mode=755)
tmpfs (rw,nosuid,nodev,relatime,mode=755)
gpfs (rw,nosuid,nodev,relatime)
nfs (rw,nosuid,nodev,relatime,vers=3,rsize=131072,wsize=524288,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=172.18.95.221,mountvers=3,mountport=20048,mountproto=tcp,local_lock=none,addr=172.18.95.221)
proc (rw,relatime)
autofs (rw,relatime,fd=35,pgrp=1,timeout=0,minproto=5,maxproto=5,direct,pipe_ino=436)
binfmt_misc (rw,relatime)
sysfs (rw,relatime)
securityfs (rw,nosuid,nodev,noexec,relatime)
tmpfs (ro,nosuid,nodev,noexec,mode=755)
cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)
cgroup (rw,nosuid,nodev,noexec,relatime,rdma)
cgroup (rw,nosuid,nodev,noexec,relatime,memory)
cgroup (rw,nosuid,nodev,noexec,relatime,freezer)
cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)
cgroup (rw,nosuid,nodev,noexec,relatime,net_cls,net_prio)
cgroup (rw,nosuid,nodev,noexec,relatime,devices)
cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)
cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)
cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)
cgroup (rw,nosuid,nodev,noexec,relatime,pids)
cgroup (rw,nosuid,nodev,noexec,relatime,blkio)
pstore (rw,nosuid,nodev,noexec,relatime)
bpf (rw,nosuid,nodev,noexec,relatime,mode=700)
configfs (rw,relatime)
debugfs (rw,relatime)
tracefs (rw,relatime)
fusectl (rw,relatime)
nfs (rw,nosuid,nodev,relatime,vers=3,rsize=131072,wsize=524288,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=172.18.95.221,mountvers=3,mountport=20048,mountproto=tcp,local_lock=none,addr=172.18.95.221)
xfs (rw,nosuid,nodev,attr2,inode64,logbufs=8,logbsize=32k,usrquota)
tmpfs (rw,nosuid,nodev,relatime,mode=755)
tmpfs (rw,nosuid,relatime,size=16384k,uid=7044184,gid=7001326)
tmpfs (rw,nosuid,relatime,size=16384k,uid=7044184,gid=7001326)
tmpfs (rw,nosuid,relatime,size=16384k,uid=7044184,gid=7001326)
=====================================================================

=====================================================================
User Limits
bash -c 'ulimit -a'
---------------------------------------------------------------------
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 1029827
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) 38830080
open files                      (-n) 4096
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 384776
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
=====================================================================

=====================================================================
User Limits (hard)
bash -c 'ulimit -aH'
---------------------------------------------------------------------
core file size          (blocks, -c) unlimited
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 1029827
max locked memory       (kbytes, -l) unlimited
max memory size         (kbytes, -m) 38830080
open files                      (-n) 131072
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) unlimited
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1029827
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
=====================================================================

=====================================================================
Global File Limit
cat /proc/sys/fs/file-{max,nr}
---------------------------------------------------------------------
26325721
15104	0	26325721
=====================================================================

=====================================================================
Memory config
sysctl vm
---------------------------------------------------------------------
vm.admin_reserve_kbytes = 8192
vm.block_dump = 0
vm.compact_unevictable_allowed = 1
vm.compaction_proactiveness = 0
vm.dirty_background_bytes = 0
vm.dirty_background_ratio = 10
vm.dirty_bytes = 0
vm.dirty_expire_centisecs = 3000
vm.dirty_ratio = 20
vm.dirty_writeback_centisecs = 500
vm.dirtytime_expire_seconds = 43200
vm.drop_caches = 3
vm.extfrag_threshold = 500
vm.force_cgroup_v2_swappiness = 0
vm.hugetlb_shm_group = 0
vm.laptop_mode = 0
vm.legacy_va_layout = 0
vm.legacy_willneed_readahead = 0
vm.lowmem_reserve_ratio = 256	256	32	0	0
vm.max_map_count = 65530
vm.memory_failure_early_kill = 0
vm.memory_failure_recovery = 1
vm.min_free_kbytes = 225280
vm.min_slab_ratio = 5
vm.min_unmapped_ratio = 1
vm.mmap_min_addr = 4096
vm.nr_hugepages = 0
vm.nr_hugepages_mempolicy = 0
vm.nr_overcommit_hugepages = 0
vm.numa_stat = 1
vm.numa_zonelist_order = Node
vm.oom_dump_tasks = 1
vm.oom_kill_allocating_task = 0
vm.overcommit_kbytes = 0
vm.overcommit_memory = 0
vm.overcommit_ratio = 50
vm.page-cluster = 3
vm.page_lock_unfairness = 5
vm.panic_on_oom = 0
vm.percpu_pagelist_fraction = 0
vm.stat_interval = 1
vm.swappiness = 0
vm.user_reserve_kbytes = 131072
vm.vfs_cache_pressure = 100
vm.watermark_boost_factor = 15000
vm.watermark_scale_factor = 10
vm.zone_reclaim_mode = 0
=====================================================================

=====================================================================
THP memory config
cat /sys/kernel/mm/*transparent_hugepage/enabled
---------------------------------------------------------------------
[always] madvise never
=====================================================================

=====================================================================
cgroups
cat /proc/self/cgroup
---------------------------------------------------------------------
12:blkio:/system.slice/slurmd.service
11:pids:/system.slice/slurmd.service
10:hugetlb:/
9:cpu,cpuacct:/system.slice/slurmd.service
8:perf_event:/
7:devices:/slurm/uid_7044184/job_9816841/step_batch/task_0
6:net_cls,net_prio:/
5:cpuset:/slurm/uid_7044184/job_9816841/step_batch
4:freezer:/slurm/uid_7044184/job_9816841/step_batch
3:memory:/slurm/uid_7044184/job_9816841/step_batch/task_0
2:rdma:/
1:name=systemd:/system.slice/slurmd.service
=====================================================================

=====================================================================
cgroup mem stats
cat /sys/fs/cgroup/memory/slurm/uid_7044184/job_9816841/step_batch/task_0/memory.stat
---------------------------------------------------------------------
cache 637038592
rss 811810816
rss_huge 482344960
shmem 16384
mapped_file 15572992
dirty 4096
writeback 0
swap 0
pgpgin 26813151
pgpgout 26584708
pgfault 61278042
pgmajfault 6552
inactive_anon 817352704
active_anon 155648
inactive_file 311980032
active_file 324816896
unevictable 0
hierarchical_memory_limit 39762001920
hierarchical_memsw_limit 39762001920
total_cache 637038592
total_rss 811810816
total_rss_huge 482344960
total_shmem 16384
total_mapped_file 15572992
total_dirty 4096
total_writeback 0
total_swap 0
total_pgpgin 26813151
total_pgpgout 26584708
total_pgfault 61278042
total_pgmajfault 6552
total_inactive_anon 817352704
total_active_anon 155648
total_inactive_file 311980032
total_active_file 324816896
total_unevictable 0
=====================================================================

=====================================================================
memory soft limit
cat /sys/fs/cgroup/memory/slurm/uid_7044184/job_9816841/step_batch/task_0/memory.*soft_limit_in_bytes
---------------------------------------------------------------------
9223372036854771712
=====================================================================

=====================================================================
memory hard limit
cat /sys/fs/cgroup/memory/slurm/uid_7044184/job_9816841/step_batch/task_0/memory.limit_in_bytes
---------------------------------------------------------------------
9223372036854771712
=====================================================================

=====================================================================
memory swap limit
cat /sys/fs/cgroup/memory/slurm/uid_7044184/job_9816841/step_batch/task_0/memory.memsw.limit_in_bytes
---------------------------------------------------------------------
9223372036854771712
=====================================================================

=====================================================================
Container
[ -e /.dockerenv ] || [ -e /.dockerinit ] || [ ! -z "$container" ] || grep -m 1 -E 'docker|lxc' /proc/1/cgroup > /dev/null && echo 'Detected'
---------------------------------------------------------------------
=====================================================================

=====================================================================
init process
head -n 1 /proc/1/sched | cut -d ' ' -f 1
---------------------------------------------------------------------
systemd
=====================================================================

=====================================================================
SGE Submit
which qsub
---------------------------------------------------------------------
=====================================================================

=====================================================================
LSF Submit
which bsub
---------------------------------------------------------------------
=====================================================================

=====================================================================
BCL2FASTQ 1
which configureBclToFastq.pl
---------------------------------------------------------------------
=====================================================================

=====================================================================
BCL2FASTQ 2
which bcl2fastq
---------------------------------------------------------------------
=====================================================================

=====================================================================
Java
which java
---------------------------------------------------------------------
=====================================================================

=====================================================================
10X Refdata
echo $TENX_REFDATA
---------------------------------------------------------------------

=====================================================================

=====================================================================
10X Refdata Version
cat $TENX_REFDATA/version
---------------------------------------------------------------------
=====================================================================

=====================================================================
qconf
which qconf
---------------------------------------------------------------------
=====================================================================

=====================================================================
slurm info
sinfo -O nodes,maxcpuspernode,memory,time
---------------------------------------------------------------------
=====================================================================

=====================================================================
MRP
mrp --version
---------------------------------------------------------------------
v4.0.6
=====================================================================

=====================================================================
mrp templates
ls $(dirname $(dirname $(which mrp)))/jobmanagers/*.template
---------------------------------------------------------------------
.:
Control-CAF

.:
Control-CAF

/usr:
bin
games
include
lib
local
sbin
share
src
=====================================================================

